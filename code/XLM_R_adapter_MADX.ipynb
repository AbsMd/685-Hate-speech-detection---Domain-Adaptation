{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "edOh9ooiIW1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3551ca4-d8f0-4ced-8a05-1811b55a73ca"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Confirm that the GPU is detected\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device: Tesla T4, n_gpu: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtqS2e5fxpqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e105190a-989a-48ee-e32c-5ab1f67486c5"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/adapter-hub/adapter-transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKN2QWyzvaTR",
        "outputId": "d3c7601e-0624-4625-9649-322269073240"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/adapter-hub/adapter-transformers.git\n",
            "  Cloning https://github.com/adapter-hub/adapter-transformers.git to /tmp/pip-req-build-q1o5pa55\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/adapter-hub/adapter-transformers.git /tmp/pip-req-build-q1o5pa55\n",
            "  Resolved https://github.com/adapter-hub/adapter-transformers.git to commit b7c9c38888f7707d206860eb1c0f7366a1776ed0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers==3.2.1) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers==3.2.1) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.2.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.2.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.2.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.2.1) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import XLMRobertaForSequenceClassification, AdamW, XLMRobertaConfig\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def tokenize_and_format(sentences):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\", do_lower_case=False)\n",
        "\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sentence in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sentence,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 64,           # Pad & truncate all sentences.\n",
        "                          padding = 'max_length',\n",
        "                          truncation = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "\n",
        "      # Add the encoded sentence to the list.\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "  return input_ids, attention_masks\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "metadata": {
        "id": "xvR4_nyGmnDf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8XIL7wPovVX"
      },
      "source": [
        "The cell below imports some helper functions we wrote to demonstrate the task on the sample tweet dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Taseb33Sovg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "68e94e6d-e223-4ca1-ef2c-4c090da7a281"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/NLP Ethos - ethos.csv\")\n",
        "data = data.sample(frac = 1).reset_index(drop=True)\n",
        "total = data.shape[0]\n",
        "train_data = data.iloc[:801, 2:]\n",
        "validation_data_eng = data.iloc[801:944, 2:]\n",
        "validation_data_hindi = data.iloc[944:, 2:]\n",
        "train_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Label                                        Translation\n",
              "0      1  लगभग सभी असभ्य संस्कृतियों और मरुस्थल धर्मों क...\n",
              "1      1                      ट्रांसजेंडर बहुत ही घृणित हैं\n",
              "2      0  ट्रम्प एक झूठा और एक बेवकूफ, एक डौश बैग, नार्स...\n",
              "3      0  मैं सुबह 4 बजे शुरू होने वाली 10 घंटे की ड्यूट...\n",
              "4      1             I wish HIV to your butthole male whore"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1c8e4ba-159e-4d6f-98fa-945c1683999d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>लगभग सभी असभ्य संस्कृतियों और मरुस्थल धर्मों क...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ट्रांसजेंडर बहुत ही घृणित हैं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>ट्रम्प एक झूठा और एक बेवकूफ, एक डौश बैग, नार्स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>मैं सुबह 4 बजे शुरू होने वाली 10 घंटे की ड्यूट...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>I wish HIV to your butthole male whore</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1c8e4ba-159e-4d6f-98fa-945c1683999d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1c8e4ba-159e-4d6f-98fa-945c1683999d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1c8e4ba-159e-4d6f-98fa-945c1683999d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data_eng.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EIGdqwWRy52b",
        "outputId": "bcda9a90-3580-4c0d-fc63-18e8f8ee30d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                        Translation\n",
              "801      1                                       gays suckï»¿\n",
              "802      1  he should have put some nigger brains on the p...\n",
              "803      1  Are you mentally handicapped or this is your n...\n",
              "804      0  मुझे लगता है कि रिपोर्टर को एक पिस्तौल या कुछ ...\n",
              "805      1  अगर पुरुषों को महिलाओं को नहीं मारना चाहिए क्य..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d83c9ab4-c327-45b8-bef0-062bc746f28d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>1</td>\n",
              "      <td>gays suckï»¿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>1</td>\n",
              "      <td>he should have put some nigger brains on the p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>1</td>\n",
              "      <td>Are you mentally handicapped or this is your n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>0</td>\n",
              "      <td>मुझे लगता है कि रिपोर्टर को एक पिस्तौल या कुछ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>1</td>\n",
              "      <td>अगर पुरुषों को महिलाओं को नहीं मारना चाहिए क्य...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d83c9ab4-c327-45b8-bef0-062bc746f28d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d83c9ab4-c327-45b8-bef0-062bc746f28d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d83c9ab4-c327-45b8-bef0-062bc746f28d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data_hindi.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8Zd5CsNQy8aa",
        "outputId": "349119c4-f7fa-4589-b321-bda2e7181b5e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                        Translation\n",
              "944      1  इस सीधे आदमी को अपमानित करना। सीधे लोग उसे पसं...\n",
              "945      1  पुरुष सुंदरता देख सकते हैं, इसलिए वे अश्वेत मह...\n",
              "946      1  कोई बलपूर्वक परिवर्तित कैसे किया जा सकता है? य...\n",
              "947      1  This is just crazy liberal satanic crap. Don't...\n",
              "948      0      It's killing me seeing gays treated like that"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14e89055-8f07-46d4-a5ba-90ddddf8d3ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>944</th>\n",
              "      <td>1</td>\n",
              "      <td>इस सीधे आदमी को अपमानित करना। सीधे लोग उसे पसं...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>945</th>\n",
              "      <td>1</td>\n",
              "      <td>पुरुष सुंदरता देख सकते हैं, इसलिए वे अश्वेत मह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>946</th>\n",
              "      <td>1</td>\n",
              "      <td>कोई बलपूर्वक परिवर्तित कैसे किया जा सकता है? य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>947</th>\n",
              "      <td>1</td>\n",
              "      <td>This is just crazy liberal satanic crap. Don't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948</th>\n",
              "      <td>0</td>\n",
              "      <td>It's killing me seeing gays treated like that</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14e89055-8f07-46d4-a5ba-90ddddf8d3ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14e89055-8f07-46d4-a5ba-90ddddf8d3ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14e89055-8f07-46d4-a5ba-90ddddf8d3ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training data is:', train_data.shape)\n",
        "print('Shape of validation data (eng) is:', validation_data_eng.shape)\n",
        "print('Shape of validation data (hindi) is:', validation_data_hindi.shape)\n",
        "\n",
        "train_len = train_data.shape[0]\n",
        "val_len_eng = validation_data_eng.shape[0]\n",
        "val_len_hindi = validation_data_hindi.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMmeeObGzAA2",
        "outputId": "e26dd62c-c6fb-48ef-b60b-5284e053b8b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data is: (801, 2)\n",
            "Shape of validation data (eng) is: (143, 2)\n",
            "Shape of validation data (hindi) is: (78, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.countplot(x=train_data['Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "DBNpAxayzCu9",
        "outputId": "c67b4c1e-9827-4b3c-f2c3-37c353aede7d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Label', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.countplot(x=validation_data_eng['Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "DGOxWyDszDSK",
        "outputId": "7cae4374-b89c-41a4-80f4-08a874633cfc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Label', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.countplot(x=validation_data_hindi['Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "W1li1kaszGwi",
        "outputId": "8e73a720-635a-40c3-da32-0cabef7e46cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Label', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGhkeLQlNNr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cec83a-c877-4b17-add2-fbacae0a8438"
      },
      "source": [
        "text = data.Translation.values\n",
        "labels = data.Label.values\n",
        "\n",
        "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "input_ids, attention_masks = tokenize_and_format(text)\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', text[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  लगभग सभी असभ्य संस्कृतियों और मरुस्थल धर्मों के लोग एक जैसे होते हैं।\n",
            "Token IDs: tensor([     0,  96671,  17415,  20571,  53778, 130002,   7549,    871,   3396,\n",
            "         16727, 118640,  15858,   1302,    287,  19181,    967,  38380,   8358,\n",
            "          1293,    125,      2,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGgeZ3M0UWs0"
      },
      "source": [
        "train_data = data.iloc[:801, 2:]\n",
        "validation_data_eng = data.iloc[801:944, 2:]\n",
        "validation_data_hindi = data.iloc[944:, 2:]\n",
        "\n",
        "# make lists of 3-tuples (already shuffled the dataframe in cell above)\n",
        "\n",
        "train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(801)]\n",
        "val_set_eng = [(input_ids[i], attention_masks[i], labels[i]) for i in range(801, 944)]\n",
        "val_set_hindi = [(input_ids[i], attention_masks[i], labels[i]) for i in range(944, total)]\n",
        "\n",
        "\n",
        "train_text = [text[i] for i in range(801)]\n",
        "val_text_eng = [text[i] for i in range(801, 944)]\n",
        "val_text_hindi = [text[i] for i in range(944, total)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_eng = pd.read_csv(\"/content/final dataset - eng - Sheet1.csv\")\n",
        "data_eng = data_eng.sample(frac = 1).reset_index(drop=True)\n",
        "test_data_eng = data_eng.iloc[:, 1:]\n",
        "test_data_eng.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oW4jmf0CpvoJ",
        "outputId": "04ef16ce-b8b9-4f34-d9d0-bab74df3b12c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                       Translations\n",
              "0      1  You’re right. This is beneath me. Like your mo...\n",
              "1      0  The only reason I came tonight was to get my p...\n",
              "2      1  But instead of vampires, we had meth heads. Bu...\n",
              "3      1      Well, dead whore on TV, live one in real life\n",
              "4      1               There are a lot of bitches out there"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc0c216a-2b73-4c50-b5f0-963dec0bc6c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Translations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>You’re right. This is beneath me. Like your mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>The only reason I came tonight was to get my p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>But instead of vampires, we had meth heads. Bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Well, dead whore on TV, live one in real life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>There are a lot of bitches out there</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc0c216a-2b73-4c50-b5f0-963dec0bc6c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc0c216a-2b73-4c50-b5f0-963dec0bc6c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc0c216a-2b73-4c50-b5f0-963dec0bc6c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_hindi = pd.read_csv(\"/content/final_dataset - hindi - Sheet1.csv\")\n",
        "data_hindi = data_hindi.sample(frac = 1).reset_index(drop=True)\n",
        "test_data_hindi = data_hindi.iloc[:, 1:]\n",
        "test_data_hindi.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iKcdcyeHOapP",
        "outputId": "3b340ae3-2e40-4e6b-958f-c618ef29c778"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                       Translations\n",
              "0      0  मैं अपने माता-पिता को अब अपने भविष्य को नियंत्...\n",
              "1      1  मम्मी, पैपा, मैं आपको मेरी नई दिलचस्पी, पेनी स...\n",
              "2      1  तुम मेरी एंटुराज के एक अमूल्य अंग साबित हो रहे...\n",
              "3      1  नहीं, अब R. केली से कुछ गाने बजाने का और चुम्ब...\n",
              "4      1  क्या आप चाहेंगे कि मैं आपको एक और कारण बताऊं क..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0e500d4-f6ef-4f45-b470-3c122bf933e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Translations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>मैं अपने माता-पिता को अब अपने भविष्य को नियंत्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>मम्मी, पैपा, मैं आपको मेरी नई दिलचस्पी, पेनी स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>तुम मेरी एंटुराज के एक अमूल्य अंग साबित हो रहे...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>नहीं, अब R. केली से कुछ गाने बजाने का और चुम्ब...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>क्या आप चाहेंगे कि मैं आपको एक और कारण बताऊं क...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0e500d4-f6ef-4f45-b470-3c122bf933e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0e500d4-f6ef-4f45-b470-3c122bf933e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0e500d4-f6ef-4f45-b470-3c122bf933e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text_eng = test_data_eng.Translations.values\n",
        "test_labels_eng = test_data_eng.label.values\n",
        "test_len_eng = test_data_eng.shape[0]\n",
        "\n",
        "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "test_input_ids_eng, test_attention_masks_eng = tokenize_and_format(test_text_eng)\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids_eng = torch.cat(test_input_ids_eng, dim=0)\n",
        "test_attention_masks_eng = torch.cat(test_attention_masks_eng, dim=0)\n",
        "test_labels_eng = torch.tensor(test_labels_eng)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_text_eng[0])\n",
        "print('Token IDs:', test_input_ids_eng[0])\n",
        "\n",
        "test_set_eng = [(test_input_ids_eng[i], test_attention_masks_eng[i], test_labels_eng[i]) for i in range(test_len_eng)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTTrZdwTqzjp",
        "outputId": "2eebcb99-e73d-4bf2-f685-84f5342042d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  You’re right. This is beneath me. Like your mother was last night\n",
            "Token IDs: tensor([    0,  2583,    26,   107,  7108,     5,  3293,    83,  9149, 10519,\n",
            "          163,     5, 18852,   935, 42732,   509,  4568, 17431,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text_hindi = test_data_hindi.Translations.values\n",
        "test_labels_hindi = test_data_hindi.label.values\n",
        "test_len_hindi = test_data_hindi.shape[0]\n",
        "\n",
        "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "test_input_ids_hindi, test_attention_masks_hindi = tokenize_and_format(test_text_hindi)\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids_hindi = torch.cat(test_input_ids_hindi, dim=0)\n",
        "test_attention_masks_hindi = torch.cat(test_attention_masks_hindi, dim=0)\n",
        "test_labels_hindi = torch.tensor(test_labels_hindi)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_text_hindi[0])\n",
        "print('Token IDs:', test_input_ids_hindi[0])\n",
        "\n",
        "test_set_hindi = [(test_input_ids_hindi[i], test_attention_masks_hindi[i], test_labels_hindi[i]) for i in range(test_len_hindi)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec_CProcPAoP",
        "outputId": "1f998bce-a470-4f7b-a72d-b10aa11fcb6c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  मैं अपने माता-पिता को अब अपने भविष्य को नियंत्रित करने नहीं दूंगा। अब तो समय है उनसे मुकाबले का।\n",
            "Token IDs: tensor([     0,  10399,   5564, 104399,      9,  11524,   1480,    629,   4849,\n",
            "          5564,  45389,    629,   5366, 108734,   3282,   4050,   2191,   8771,\n",
            "        196426,    125,   4849,   2073,   6927,    460, 163290, 212638,    641,\n",
            "           125,      2,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPo640_ZlEPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c1dc5d-2704-42b7-bf65-5730a9fc8cb3"
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification, AdamW, XLMRobertaConfig\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    \"xlm-roberta-base\", # Use the base XLM-Roberta model\n",
        "    num_labels = 2, # The number of output labels\n",
        "    output_attentions = False, # Whether the model returns attention weights\n",
        "    output_hidden_states = False, # Whether the model returns all hidden states\n",
        ")\n",
        "\n",
        "from transformers.adapters import PfeifferInvConfig\n",
        "\n",
        "config = PfeifferInvConfig()\n",
        "model.add_adapter(\"lang_adapter\", config=config)\n",
        "model.set_active_adapters(\"lang_adapter\")\n",
        "\n",
        "from transformers.adapters import LoRAConfig\n",
        "\n",
        "'''config = LoRAConfig(r=8, alpha=16)\n",
        "model.add_adapter(\"lora_adapter\", config=config)\n",
        "model.set_active_adapters(\"lora_adapter\")'''\n",
        "\n",
        "# Tell PyTorch to run this model on the GPU\n",
        "model.cuda()\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (shared_parameters): ModuleDict()\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (shared_parameters): ModuleDict()\n",
              "    (invertible_adapters): ModuleDict(\n",
              "      (lang_adapter): NICECouplingBlock(\n",
              "        (F): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
              "          (1): Activation_Function_Class(\n",
              "            (f): ReLU()\n",
              "          )\n",
              "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
              "        )\n",
              "        (G): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
              "          (1): Activation_Function_Class(\n",
              "            (f): ReLU()\n",
              "          )\n",
              "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(\n",
              "                in_features=768, out_features=768, bias=True\n",
              "                (loras): ModuleDict()\n",
              "              )\n",
              "              (key): Linear(\n",
              "                in_features=768, out_features=768, bias=True\n",
              "                (loras): ModuleDict()\n",
              "              )\n",
              "              (value): Linear(\n",
              "                in_features=768, out_features=768, bias=True\n",
              "                (loras): ModuleDict()\n",
              "              )\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (prefix_tuning): PrefixTuningShim(\n",
              "                (prefix_gates): ModuleDict()\n",
              "                (pool): PrefixTuningPool(\n",
              "                  (prefix_tunings): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict()\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(\n",
              "              in_features=768, out_features=3072, bias=True\n",
              "              (loras): ModuleDict()\n",
              "            )\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(\n",
              "              in_features=3072, out_features=768, bias=True\n",
              "              (loras): ModuleDict()\n",
              "            )\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (adapters): ModuleDict(\n",
              "              (lang_adapter): Adapter(\n",
              "                (non_linearity): Activation_Function_Class(\n",
              "                  (f): ReLU()\n",
              "                )\n",
              "                (adapter_down): Sequential(\n",
              "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
              "                  (1): Activation_Function_Class(\n",
              "                    (f): ReLU()\n",
              "                  )\n",
              "                )\n",
              "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
              "              )\n",
              "            )\n",
              "            (adapter_fusion_layer): ModuleDict()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (prefix_tuning): PrefixTuningPool(\n",
              "      (prefix_tunings): ModuleDict()\n",
              "    )\n",
              "  )\n",
              "  (classifier): XLMRobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd2JdC6IletV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba90c67d-3964-4e04-e363-99c5587d4a90"
      },
      "source": [
        "batch_size = 50\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5, # args.learning_rate - default is 5e-5\n",
        "                  eps = 15e-8 # args.adam_epsilon  - default is 1e-8\n",
        "                )\n",
        "epochs = 10"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_Mzr-kd5RaY"
      },
      "source": [
        "import numpy as np\n",
        "# function to get validation accuracy\n",
        "def get_validation_performance(val_set, val_len):\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    batch_size = 20\n",
        "\n",
        "    num_batches = int(val_len/batch_size) + 1\n",
        "\n",
        "    total_correct = 0\n",
        "    mismatch_ids = []\n",
        "\n",
        "    for i in range(num_batches):\n",
        "      #print(i)\n",
        "      end_index = min(batch_size * (i+1), len(val_set))\n",
        "      #print(end_index)\n",
        "      #print(i*batch_size)\n",
        "\n",
        "      batch = val_set[i*batch_size:end_index]\n",
        "      \n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "      \n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device)\n",
        "        \n",
        "      # Tell pytorch not to bother with constructing the compute graph during\n",
        "      # the forward pass, since this is only needed for backprop (training).\n",
        "      with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the number of correctly labeled examples in batch\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "        labels_flat = label_ids.flatten()\n",
        "\n",
        "        \n",
        "        batch_mismatch_ids = [index for index, elem in enumerate(labels_flat) if elem!=pred_flat[index]]\n",
        "        batch_mismatch_ids = [index + i*batch_size for index in batch_mismatch_ids]\n",
        "        print(batch_mismatch_ids)\n",
        "        mismatch_ids += batch_mismatch_ids\n",
        "\n",
        "        num_correct = np.sum(pred_flat == labels_flat)\n",
        "        total_correct += num_correct\n",
        "        \n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_correct / len(val_set)\n",
        "    return mismatch_ids, avg_val_accuracy"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTf_ipbjWNoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6677106d-8282-427c-e19e-f527904bf719"
      },
      "source": [
        "import random\n",
        "# Set max_split_size_mb to 200 MB\n",
        "#torch.cuda.set_per_process_memory_fraction(1, device=None)\n",
        "\n",
        "# training loop\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "    #print(train_len)\n",
        "    # For each batch of training data...\n",
        "    num_batches = int(train_len/batch_size) + 1\n",
        "    #print(batch_size)\n",
        "    #print(num_batches)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "      #print(i)\n",
        "      end_index = min(batch_size * (i+1), len(train_set))\n",
        "\n",
        "      batch = train_set[i*batch_size:end_index]\n",
        "      #print(len(batch))\n",
        "\n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "\n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device)\n",
        "\n",
        "      #print(b_input_ids.shape)\n",
        "\n",
        "      # Clear the previously calculated gradient\n",
        "      model.zero_grad()        \n",
        "\n",
        "      # Perform a forward pass (evaluate the model on this training batch).\n",
        "      # Perform a forward pass (evaluate the model on this training batch).\n",
        "      outputs = model(b_input_ids, \n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask, \n",
        "                      labels=b_labels)\n",
        "      loss = outputs.loss\n",
        "      logits = outputs.logits\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      # Perform a backward pass to calculate the gradients.\n",
        "      loss.backward()\n",
        "\n",
        "      # Update parameters and take a step using the computed gradient.\n",
        "      optimizer.step()\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set. Implement this function in the cell above.\n",
        "    print(f\"Total loss: {total_train_loss}\")\n",
        "    _, val_acc_eng = get_validation_performance(val_set_eng, val_len_eng)\n",
        "    print(f\"Validation accuracy English: {val_acc_eng}\")\n",
        "    _, val_acc_hindi = get_validation_performance(val_set_hindi, val_len_hindi)\n",
        "    print(f\"Validation accuracy Hindi: {val_acc_hindi}\")\n",
        "    \n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "Total loss: 11.825275897979736\n",
            "[0, 1, 2, 4, 5, 6, 7, 8, 12, 15, 16]\n",
            "[20, 23, 27, 28, 33, 38]\n",
            "[40, 41, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 56, 57]\n",
            "[60, 61, 64, 65, 66, 68, 71, 73, 74, 75, 76, 77, 78, 79]\n",
            "[80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98]\n",
            "[102, 103, 105, 106, 107, 109, 110, 113, 115, 116, 117]\n",
            "[120, 121, 125, 126, 128, 130, 131, 133, 134, 135, 136, 139]\n",
            "[]\n",
            "Validation accuracy English: 0.4195804195804196\n",
            "[0, 1, 2, 3, 10, 11, 13, 14, 15, 16, 17, 19]\n",
            "[21, 22, 24, 27, 28, 30, 31, 32, 33, 34, 35]\n",
            "[41, 42, 43, 44, 45, 47, 48, 49, 53, 54, 55, 58]\n",
            "[60, 63, 64, 65, 66, 67, 68, 69, 71, 74, 75, 76]\n",
            "Validation accuracy Hindi: 0.3974358974358974\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "Total loss: 11.718595683574677\n",
            "[2, 4, 7, 8, 12, 15, 16]\n",
            "[28, 29, 31, 33, 34, 38, 39]\n",
            "[40, 41, 42, 45, 46, 48, 52, 53, 56]\n",
            "[64, 65, 66, 71, 73, 75, 77, 78, 79]\n",
            "[80, 83, 85, 87, 90, 94, 96, 98]\n",
            "[103, 105, 107, 108, 109, 113, 115]\n",
            "[120, 125, 128, 131, 135, 139]\n",
            "[]\n",
            "Validation accuracy English: 0.6293706293706294\n",
            "[3, 9, 10, 13, 14, 15, 16]\n",
            "[22, 28, 30, 31, 32, 35, 36]\n",
            "[44, 46, 53, 55, 58]\n",
            "[66, 67, 68, 69, 76]\n",
            "Validation accuracy Hindi: 0.6923076923076923\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "Total loss: 11.333363771438599\n",
            "[2, 4, 7, 8, 12, 16]\n",
            "[28, 29, 31, 33, 34, 39]\n",
            "[40, 41, 42, 46, 48, 52, 53, 56]\n",
            "[64, 65, 66, 68, 71, 75, 77, 78, 79]\n",
            "[80, 85, 87, 90, 96]\n",
            "[103, 105, 107, 108, 109, 112, 113]\n",
            "[120, 125, 128, 135, 139]\n",
            "[]\n",
            "Validation accuracy English: 0.6783216783216783\n",
            "[0, 3, 5, 9, 10, 13, 14, 15, 16, 18]\n",
            "[22, 27, 28, 30, 31, 32, 33, 35, 36, 39]\n",
            "[44, 46, 53, 55, 58]\n",
            "[66, 67, 68, 69, 76]\n",
            "Validation accuracy Hindi: 0.6153846153846154\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "Total loss: 11.073332130908966\n",
            "[9, 11, 12]\n",
            "[21, 22, 24, 28, 29, 31, 34, 39]\n",
            "[40, 41, 43, 46, 52, 56, 58]\n",
            "[63, 64, 66, 70, 71, 77, 79]\n",
            "[80, 85, 87, 96]\n",
            "[103, 108, 109, 112, 119]\n",
            "[120, 123, 128, 139]\n",
            "[142]\n",
            "Validation accuracy English: 0.7272727272727273\n",
            "[0, 5, 6, 9, 10, 13, 14, 16, 18]\n",
            "[25, 30, 31, 32, 35, 36, 39]\n",
            "[46, 51, 55, 58]\n",
            "[66, 67, 69]\n",
            "Validation accuracy Hindi: 0.7051282051282052\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "Total loss: 10.480091035366058\n",
            "[3, 9, 11, 12]\n",
            "[21, 22, 28, 29, 31, 34, 36, 39]\n",
            "[40, 41, 43, 46, 50, 52, 56, 58, 59]\n",
            "[63, 64, 69, 70, 77, 79]\n",
            "[80, 85, 92, 96]\n",
            "[103, 108, 109, 112, 119]\n",
            "[122, 123, 129, 139]\n",
            "[142]\n",
            "Validation accuracy English: 0.7132867132867133\n",
            "[4, 5, 6, 7, 9, 10, 14, 16, 18]\n",
            "[25, 30, 32, 35, 36, 39]\n",
            "[46, 51, 55, 56]\n",
            "[66, 67, 68, 69, 77]\n",
            "Validation accuracy Hindi: 0.6923076923076923\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "Total loss: 9.488584816455841\n",
            "[2, 3, 6, 11, 12]\n",
            "[22, 28, 31, 32, 34, 36, 39]\n",
            "[40, 41, 42, 46, 52, 56, 59]\n",
            "[63, 64, 69, 77, 79]\n",
            "[80]\n",
            "[103, 108, 109, 112]\n",
            "[120, 122, 125, 139]\n",
            "[]\n",
            "Validation accuracy English: 0.7692307692307693\n",
            "[4, 5, 6, 9, 10, 13, 14, 16, 18]\n",
            "[25, 30, 31, 32]\n",
            "[46, 56]\n",
            "[66, 67, 68, 69, 73, 76]\n",
            "Validation accuracy Hindi: 0.7307692307692307\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "Total loss: 8.47846394777298\n",
            "[6, 9, 11, 12]\n",
            "[21, 22, 28, 31, 32, 36, 39]\n",
            "[40, 41, 42, 56, 57]\n",
            "[64, 66, 77, 79]\n",
            "[80, 85, 96]\n",
            "[103, 108, 109, 112, 119]\n",
            "[125, 139]\n",
            "[]\n",
            "Validation accuracy English: 0.7902097902097902\n",
            "[4, 5, 6, 9, 10, 13, 14, 16, 18]\n",
            "[25, 28, 30, 32, 35]\n",
            "[56]\n",
            "[66, 67, 68, 69, 76]\n",
            "Validation accuracy Hindi: 0.7435897435897436\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "Total loss: 7.003915518522263\n",
            "[6, 11, 12]\n",
            "[21, 22, 28, 31, 32, 34, 36, 39]\n",
            "[40, 41, 56, 57, 59]\n",
            "[64, 66, 76, 77, 79]\n",
            "[80, 85, 87, 96]\n",
            "[103, 108, 109, 112, 119]\n",
            "[125, 139]\n",
            "[]\n",
            "Validation accuracy English: 0.7762237762237763\n",
            "[0, 4, 5, 9, 10, 13, 14, 16, 18]\n",
            "[25, 28, 30, 32]\n",
            "[45, 56]\n",
            "[66, 67, 68, 69, 76]\n",
            "Validation accuracy Hindi: 0.7435897435897436\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "Total loss: 5.64372855424881\n",
            "[3, 6, 11, 12]\n",
            "[21, 22, 28, 31, 32, 34, 36, 39]\n",
            "[40, 41, 50, 56, 57, 59]\n",
            "[64, 66, 69, 70, 77, 79]\n",
            "[82, 85]\n",
            "[103, 108, 109, 112, 119]\n",
            "[139]\n",
            "[142]\n",
            "Validation accuracy English: 0.7692307692307693\n",
            "[0, 4, 5, 9, 10, 14, 16, 18]\n",
            "[25, 30, 38]\n",
            "[45, 56]\n",
            "[66, 68, 69, 76]\n",
            "Validation accuracy Hindi: 0.782051282051282\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "Total loss: 4.637242630124092\n",
            "[3, 11, 12]\n",
            "[21, 22, 24, 28, 31, 32, 34, 36, 39]\n",
            "[40, 41, 50, 56, 59]\n",
            "[64, 66, 69, 70, 79]\n",
            "[82]\n",
            "[103, 108, 109, 112, 119]\n",
            "[129, 139]\n",
            "[142]\n",
            "Validation accuracy English: 0.7832167832167832\n",
            "[0, 4, 5, 9, 10, 14, 16, 18]\n",
            "[25, 38]\n",
            "[45, 56]\n",
            "[66, 68, 69, 76]\n",
            "Validation accuracy Hindi: 0.7948717948717948\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msvZ78ii3cZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758810da-0984-4844-c367-6973b27d2c81"
      },
      "source": [
        "mismatch_ids_eng, test_acc_eng = get_validation_performance(test_set_eng, test_len_eng)\n",
        "print(test_acc_eng)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 3, 4, 5, 7, 9, 19]\n",
            "[22, 23, 28, 32, 33, 35, 36, 37, 38]\n",
            "[41, 42, 45, 48, 50, 55, 56, 59]\n",
            "[]\n",
            "0.6065573770491803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X72mumhI9WdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7fefa2-d6bd-4293-b824-a39c8534d618"
      },
      "source": [
        "## YOUR ERROR ANALYSIS CODE HERE\n",
        "## print out up to 5 test set examples (or adversarial examples) that your model gets wrong\n",
        "\n",
        "incorrect_classif_instances_eng = []\n",
        "for i in range(len(mismatch_ids_eng)):\n",
        "  incorrect_classif_instances_eng.append(test_text_eng[i])\n",
        "\n",
        "print(incorrect_classif_instances_eng)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['You’re right. This is beneath me. Like your mother was last night', \"The only reason I came tonight was to get my parents off my case. I certainly don't need to be getting this Old World crap from you.\", 'But instead of vampires, we had meth heads. But both came out at night and had messed up teeth', 'Well, dead whore on TV, live one in real life', 'There are a lot of bitches out there', \"Come on, numbnuts, it's the comic book store!\", \"Well, what are we waiting for? Let's bounce, bitches.\", \"Sheldon, don't take this the wrong way, but you're insane.\", 'Oh that gossipy bitch! No offense, Raj', 'The lucky bastard. It\\'s gotta be that stupid accent of his. \"Hello, I\\'m Sanjay Wolowitz from Bombay.\"', 'Okay, um, hey, God. What’s up? Um, I’m good, but, uh, it would be a big help to my family if you could get my brother to stop cooking meth. But no cops. Be cool', 'No. I meant that all women are slaves to their biological urges, you know? Even you. You’re a slave', 'The growing realization that you are one wacky bastard? Yep.', \"It's on, bitch!\", 'No, I had a cover story, I told everyone it was herpes. So, how’s everything going with you and Leonard?', 'Hey, you know, my mom smoked pot when she was pregnant with me, and I turned out just fine.', 'That stupid self-centered bastard wrote about our sex life on his blog.', 'Hey, look, I have peach schnapps. Thank God', \"You're just gonna sit around here and mope while Penny is out with Dr. Apu from the Kwik-E-Mart\", 'I’m saying, in the spirit of science, what is that little skank’s problem?', 'What the hell? The last time we went to the zoo, that son of a bitch made me buy him a churro', 'I’ve been doing some research on strippers', 'While I have no respect for Leslie as a scientist or human being we must acknowledge her experience in the field of promiscuity and general slutiness', 'She also goes a little overboard on the love thy neighbour. Could probably use that chat you had with Mary Magdalene. Leonard, you’re up. Wasserman, you’re on deck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mismatch_ids_hindi, test_acc_hindi = get_validation_performance(test_set_hindi, test_len_hindi)\n",
        "print(test_acc_hindi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at8-UXMiP1vy",
        "outputId": "589fec32-9296-424a-de9c-90d1b10f993c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 8, 11, 15, 18]\n",
            "[23, 24, 27, 28, 30, 31, 32, 33, 35, 38, 39]\n",
            "[41, 43, 51]\n",
            "0.5964912280701754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_classif_instances_hindi = []\n",
        "for i in range(len(mismatch_ids_hindi)):\n",
        "  incorrect_classif_instances_hindi.append(test_text_hindi[i])\n",
        "\n",
        "print(incorrect_classif_instances_hindi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSIhCqSVJhoN",
        "outputId": "1ee4b8f5-0160-4f01-b82a-48334bd498fa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['मैं अपने माता-पिता को अब अपने भविष्य को नियंत्रित करने नहीं दूंगा। अब तो समय है उनसे मुकाबले का।', 'मम्मी, पैपा, मैं आपको मेरी नई दिलचस्पी, पेनी से मिलवाना चाहती हूँ।', 'तुम मेरी एंटुराज के एक अमूल्य अंग साबित हो रहे हो।', 'नहीं, अब R. केली से कुछ गाने बजाने का और चुम्बन का समय है।', 'क्या आप चाहेंगे कि मैं आपको एक और कारण बताऊं कि पुरुष महिलाओं से बेहतर हैं?', 'तुम खूबसूरत प्रिंसेस पंचाली की जीवित प्रतिमूर्ति हो।', 'कुत्ते के बच्चो! तुम बीमार, अश्लील बेवकूफों!', ' मैंने सोचा था कि वह ओमाहा की वेश्या थी।', 'मैं लोटस के फूलों की खुशबू को आपके काले बालों में बुने हुए महसूस कर सकता हूं।', 'तुम एक स्वार्थी बेईमान हो। भगवान आपके और आपके नोबेल पुरस्कार से बचाए।', 'नहीं, हाँ, वह निश्चित रूप से एक वेश्या है। मैं मतलब वह पूरी तरह से अपने मानकों को नहीं रखती है। ', 'विनम्रता उन लोगों के लिए होती है जो अजीबोगरीब नोबेल पुरस्कार जीतते हैं, जैसे साहित्य, अर्थशास्त्र और शांति।', 'वह छोटी मोटी मोटी लड़की जो मुझे समोसे में मारती थी और मुझे अनुच्छेदी कहती थी?', 'अपने आप को नीचा मत धोखा दो। तुम बहुत आकर्षक हो। कुछ नहीं होगा अगर तुम अब और फिट रहने के लिए पिलेट्स क्लास करते हो।... पर तुममें वही कुछ नीचापन है।', 'पता चला कि मीठापन आजकल एक लड़की को नहीं बरकरार रखने के लिए काफी नहीं है।', 'यह तो बहुत अच्छा है। अब वह मोटी नहीं है।', 'मुझसे नहीं हो रहा। मैं महिलाओं से निपटने से तंग आ गया हूँ।', ' न केवल भारत में भूख लगी बच्चे हैं, बल्कि यहां एक भारतीय भूखा मर रहा है।', 'ओह, कृपया, तुम हमें ऊपर हटा नहीं सकते। हमने नोबेल पुरस्कार जीता है। कोई भी बच्चा पैदा कर सकता है।', 'ओह, शायद कुछ वर्जिन क्यूबा लिब्रेस थे जो किसी से चुंबन लेने को तैयार हो गए।', 'बेशक तुम्हें याद होगा। उतना मोटा होना कौन भूल सकता है?', 'ओह। तुम्हारा तंग करने वाला छोटा दोस्त जो मैंडरिन बोलता है, वह कहाँ है?', 'सभी व्यवसायिक और सामाजिक मीटिंग की शुरुआत और अंत में, सभी मौजूद लोगों से हाथ मिलाएं। पुरुष, महिलाएं और बच्चे।']\n"
          ]
        }
      ]
    }
  ]
}