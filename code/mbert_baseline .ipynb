{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "edOh9ooiIW1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a19097e-c8f9-4dea-db3b-c3bac91d212f"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Confirm that the GPU is detected\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device: Tesla T4, n_gpu: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtqS2e5fxpqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab45b850-9f84-451d-c86e-fb0bef7f784a"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import XLMRobertaForSequenceClassification, AdamW, XLMRobertaConfig\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def tokenize_and_format(sentences):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=False)\n",
        "\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sentence in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sentence,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 64,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          truncation = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "\n",
        "      # Add the encoded sentence to the list.\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "  return input_ids, attention_masks\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "metadata": {
        "id": "xvR4_nyGmnDf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Taseb33Sovg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "aead6236-d8c3-4756-8340-be1d30991560"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/NLP Ethos - Hindi - ethos.csv\")\n",
        "data = data.sample(frac = 1).reset_index(drop=True)\n",
        "total = data.shape[0]\n",
        "train_data = data.iloc[:801, 2:]\n",
        "train_data = train_data.sample(frac = 1).reset_index(drop=True)\n",
        "validation_data = data.iloc[801:, 2:]\n",
        "validation_data = validation_data.sample(frac = 1).reset_index(drop=True)\n",
        "train_data.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Label                                        Translation\n",
              "0      1  लकवाग्रस्त बच्चों को पत्थर फेंकना मेरा पसंदीदा...\n",
              "1      1  कुरान में साफ लिखा है जो कुरान को नहीं मानता व...\n",
              "2      0  यह फकहैड मुझे यहूदी होने पर शर्मिंदा करता है। ...\n",
              "3      1  मुझे वास्तव में आपका लहजा पसंद नहीं है। मैं आप...\n",
              "4      0  ओह, मुझे लगता है कि 13 reasons why आत्महत्या क..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebb38bf8-da89-47f3-bb7a-b90b73f4af9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>लकवाग्रस्त बच्चों को पत्थर फेंकना मेरा पसंदीदा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>कुरान में साफ लिखा है जो कुरान को नहीं मानता व...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>यह फकहैड मुझे यहूदी होने पर शर्मिंदा करता है। ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>मुझे वास्तव में आपका लहजा पसंद नहीं है। मैं आप...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>ओह, मुझे लगता है कि 13 reasons why आत्महत्या क...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebb38bf8-da89-47f3-bb7a-b90b73f4af9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebb38bf8-da89-47f3-bb7a-b90b73f4af9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebb38bf8-da89-47f3-bb7a-b90b73f4af9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czOoVldx_dv8",
        "outputId": "2a534c3f-c3e0-4c27-a0d6-8875278a9f19"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EIGdqwWRy52b",
        "outputId": "f189f5d0-2009-4c1b-a2ba-669741eb57ce"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Label                                        Translation\n",
              "0      0   इस्लाम सच्चा धर्म है। इस पर विश्वास करें भाइयों।\n",
              "1      1  यदि आप समलैंगिक हैं तो मेरे पास आपके लिए एक प्...\n",
              "2      1                                          गंदी चीनी\n",
              "3      1                 पुरुष जाति स्त्रियों की अधीनस्थ है\n",
              "4      1  उन कमीनों को लात मारो और कभी वापस मत आना। इस्ल..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fe9b236-61cc-4a60-8017-e1d2e8cd021e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>इस्लाम सच्चा धर्म है। इस पर विश्वास करें भाइयों।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>यदि आप समलैंगिक हैं तो मेरे पास आपके लिए एक प्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>गंदी चीनी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>पुरुष जाति स्त्रियों की अधीनस्थ है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>उन कमीनों को लात मारो और कभी वापस मत आना। इस्ल...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fe9b236-61cc-4a60-8017-e1d2e8cd021e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2fe9b236-61cc-4a60-8017-e1d2e8cd021e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2fe9b236-61cc-4a60-8017-e1d2e8cd021e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training data is:', train_data.shape)\n",
        "print('Shape of validation data (eng) is:', validation_data.shape)\n",
        "#print('Shape of validation data (hindi) is:', validation_data_hindi.shape)\n",
        "\n",
        "train_len = train_data.shape[0]\n",
        "val_len = validation_data.shape[0]\n",
        "#val_len_hindi = validation_data_hindi.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMmeeObGzAA2",
        "outputId": "55fa93e8-d742-4113-bd4e-f720df138678"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data is: (801, 2)\n",
            "Shape of validation data (eng) is: (221, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.countplot(x=train_data['Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "DBNpAxayzCu9",
        "outputId": "5a38f532-3815-4251-8d14-954152f9cce6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Label', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.countplot(x=validation_data['Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "DGOxWyDszDSK",
        "outputId": "eac89fa7-f32c-43b6-8ba4-0327c8374a76"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Label', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGhkeLQlNNr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cdc170-9a10-45b0-8a2a-457e79796b12"
      },
      "source": [
        "text = data.Translation.values\n",
        "labels = data.Label.values\n",
        "\n",
        "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "input_ids, attention_masks = tokenize_and_format(text)\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', text[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  नहीं ट्रम्प! हम चाहते हैं कि आप सभी अवैध अप्रवासियों को निर्वासित करें! जब मैं कहता हूं सब, मेरा मतलब है सब! अवधि! मैं»¿\n",
            "Token IDs: tensor([   101,  16791,    875,  53606,  20429,  18187,    106, 105127,    870,\n",
            "         66921,  17203,  11716,  14117,    852,  18187,  35387,    851,  15070,\n",
            "         18438,  27694,    851,  18187,  18321, 102116,  19966,  11267,    884,\n",
            "         46354,  27155,  34646,  13184,  16192,  42057,    106,  29404,    889,\n",
            "         99007,    865, 108775,  11208,    899,  15778,  14018, 110334,    117,\n",
            "         40265,  31277,    889,  11845,  11714,  18351,  10569, 110334,    106,\n",
            "           851,  15070,  32831,    106,    889,  99007,    220,    224,    102,\n",
            "             0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGgeZ3M0UWs0"
      },
      "source": [
        "train_data = data.iloc[:801, 2:]\n",
        "validation_data_eng = data.iloc[801:, 2:]\n",
        "\n",
        "# make lists of 3-tuples (already shuffled the dataframe in cell above)\n",
        "\n",
        "train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(801)]\n",
        "val_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(801, total)]\n",
        "\n",
        "\n",
        "train_text = [text[i] for i in range(801)]\n",
        "val_text = [text[i] for i in range(801, total)]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/Friends Hatespeech Multilingual Dataset - Sheet1.csv\")\n",
        "test_data = data.iloc[:, 1:3]\n",
        "test_data = test_data.sample(frac = 1).reset_index(drop=True)\n",
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oW4jmf0CpvoJ",
        "outputId": "b64196df-8984-479b-f814-214abf73d54a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                       Translations\n",
              "0      1          तो तुम बस ऐसे ही, एक आदमी हो जो नैनी है? \n",
              "1      0  मुझें नहीं पता! मैं नहीं—शायद आप थोड़ा नाराज म...\n",
              "2      1                                   तुम एक मूर्ख हो!\n",
              "3      0  हाँ, वे करते हैं! बच्चे की तरह बनना छोड़ो और म...\n",
              "4      0  ओहायो में एक गर्भवती महिला है, और उसने हमें चु..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1cf8420-cbd0-408e-a68d-25b180e96c61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Translations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>तो तुम बस ऐसे ही, एक आदमी हो जो नैनी है?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>मुझें नहीं पता! मैं नहीं—शायद आप थोड़ा नाराज म...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>तुम एक मूर्ख हो!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>हाँ, वे करते हैं! बच्चे की तरह बनना छोड़ो और म...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>ओहायो में एक गर्भवती महिला है, और उसने हमें चु...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1cf8420-cbd0-408e-a68d-25b180e96c61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1cf8420-cbd0-408e-a68d-25b180e96c61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1cf8420-cbd0-408e-a68d-25b180e96c61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = test_data.Translations.values\n",
        "test_labels = test_data.label.values\n",
        "test_len = test_data.shape[0]\n",
        "\n",
        "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "test_input_ids, test_attention_masks = tokenize_and_format(test_text)\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_text[0])\n",
        "print('Token IDs:', test_input_ids[0])\n",
        "\n",
        "test_set = [(test_input_ids[i], test_attention_masks[i], test_labels[i]) for i in range(test_len)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTTrZdwTqzjp",
        "outputId": "10441c30-5425-432c-90e9-65bde1b70856"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  तो तुम बस ऐसे ही, एक आदमी हो जो नैनी है? \n",
            "Token IDs: tensor([  101, 21042,   880, 14070, 13841,   887, 13432, 70648, 14080,   117,\n",
            "        11186,   852, 15552, 40340, 13220, 15134, 59029, 19810, 10569,   136,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPo640_ZlEPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa71cfc3-f6db-40a2-ff79-67b06f9aef96"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, XLMRobertaConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the base XLM-Roberta model\n",
        "    num_labels = 2, # The number of output labels\n",
        "    output_attentions = False, # Whether the model returns attention weights\n",
        "    output_hidden_states = False, # Whether the model returns all hidden states\n",
        ")\n",
        "\n",
        "'''from transformers.adapters import PfeifferInvConfig\n",
        "\n",
        "config = PfeifferInvConfig()\n",
        "model.add_adapter(\"lang_adapter\", config=config)\n",
        "model.set_active_adapters(\"lang_adapter\")'''\n",
        "\n",
        "# from transformers.adapters import LoRAConfig\n",
        "\n",
        "# config = LoRAConfig(r=8, alpha=16)\n",
        "# model.add_adapter(\"lora_adapter\", config=config)\n",
        "# model.set_active_adapters(\"lora_adapter\")\n",
        "\n",
        "# Tell PyTorch to run this model on the GPU\n",
        "model.cuda()\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd2JdC6IletV"
      },
      "source": [
        "batch_size = 50\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5, # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
        "                )\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
        "epochs = 10"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_Mzr-kd5RaY"
      },
      "source": [
        "import numpy as np\n",
        "# function to get validation accuracy\n",
        "def get_validation_performance(val_set, val_len):\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    num_batches = int(val_len/batch_size) + 1\n",
        "\n",
        "    total_correct = 0\n",
        "    mismatch_ids = []\n",
        "\n",
        "    for i in range(num_batches):\n",
        "      #print(i)\n",
        "      end_index = min(batch_size * (i+1), len(val_set))\n",
        "      #print(end_index)\n",
        "      #print(i*batch_size)\n",
        "\n",
        "      batch = val_set[i*batch_size:end_index]\n",
        "      \n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "      \n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device)\n",
        "        \n",
        "      # Tell pytorch not to bother with constructing the compute graph during\n",
        "      # the forward pass, since this is only needed for backprop (training).\n",
        "      with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the number of correctly labeled examples in batch\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "        labels_flat = label_ids.flatten()\n",
        "\n",
        "        \n",
        "        batch_mismatch_ids = [index for index, elem in enumerate(labels_flat) if elem!=pred_flat[index]]\n",
        "        batch_mismatch_ids = [index + i*batch_size for index in batch_mismatch_ids]\n",
        "        # print(batch_mismatch_ids)\n",
        "        mismatch_ids += batch_mismatch_ids\n",
        "\n",
        "        num_correct = np.sum(pred_flat == labels_flat)\n",
        "        total_correct += num_correct\n",
        "        \n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_correct / len(val_set)\n",
        "    return mismatch_ids, avg_val_accuracy"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTf_ipbjWNoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c919b4-0db2-44ff-b587-a031aeef077b"
      },
      "source": [
        "import random\n",
        "# Set max_split_size_mb to 200 MB\n",
        "#torch.cuda.set_per_process_memory_fraction(1, device=None)\n",
        "\n",
        "# training loop\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "    #print(train_len)\n",
        "    # For each batch of training data...\n",
        "    num_batches = int(train_len/batch_size) + 1\n",
        "    #print(batch_size)\n",
        "    #print(num_batches)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "      #print(i)\n",
        "      end_index = min(batch_size * (i+1), len(train_set))\n",
        "\n",
        "      batch = train_set[i*batch_size:end_index]\n",
        "      #print(len(batch))\n",
        "\n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "\n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device)\n",
        "\n",
        "      #print(b_input_ids.shape)\n",
        "\n",
        "      # Clear the previously calculated gradient\n",
        "      model.zero_grad()        \n",
        "\n",
        "      # Perform a forward pass (evaluate the model on this training batch).\n",
        "      # Perform a forward pass (evaluate the model on this training batch).\n",
        "      outputs = model(b_input_ids, \n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask, \n",
        "                      labels=b_labels)\n",
        "      loss = outputs.loss\n",
        "      logits = outputs.logits\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      # Perform a backward pass to calculate the gradients.\n",
        "      loss.backward()\n",
        "\n",
        "      # Update parameters and take a step using the computed gradient.\n",
        "      optimizer.step()\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set. Implement this function in the cell above.\n",
        "    print(f\"Total loss: {total_train_loss}\")\n",
        "    #_, val_acc_eng = get_validation_performance(val_set_eng, val_len_eng)\n",
        "    #print(f\"Validation accuracy English: {val_acc_eng}\")\n",
        "    _, val_acc_hindi = get_validation_performance(val_set, val_len)\n",
        "    print(f\"Validation accuracy Hindi: {val_acc_hindi}\")\n",
        "    \n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "Total loss: 11.675607442855835\n",
            "Validation accuracy Hindi: 0.583710407239819\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "Total loss: 11.1998450756073\n",
            "Validation accuracy Hindi: 0.6334841628959276\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "Total loss: 10.024749651551247\n",
            "Validation accuracy Hindi: 0.6832579185520362\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "Total loss: 8.546428374946117\n",
            "Validation accuracy Hindi: 0.6877828054298643\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "Total loss: 6.51898392662406\n",
            "Validation accuracy Hindi: 0.7420814479638009\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "Total loss: 4.363882964476943\n",
            "Validation accuracy Hindi: 0.7692307692307693\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "Total loss: 2.547900923527777\n",
            "Validation accuracy Hindi: 0.7104072398190046\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "Total loss: 2.8401631880551577\n",
            "Validation accuracy Hindi: 0.7149321266968326\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "Total loss: 1.4606567253358662\n",
            "Validation accuracy Hindi: 0.7239819004524887\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "Total loss: 1.385043633170426\n",
            "Validation accuracy Hindi: 0.6425339366515838\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msvZ78ii3cZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7d6e31-472c-4751-b6fe-b2a231f80a9c"
      },
      "source": [
        "\n",
        "mismatch_ids, test_acc = get_validation_performance(test_set, test_len)\n",
        "print(test_acc)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X72mumhI9WdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6361c3-b10a-4d01-de16-eb3bac79d26a"
      },
      "source": [
        "\n",
        "\n",
        "incorrect_classif_instances = []\n",
        "for i in range(len(mismatch_ids)):\n",
        "  incorrect_classif_instances.append(test_text[i])\n",
        "\n",
        "print(incorrect_classif_instances)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['तो तुम बस ऐसे ही, एक आदमी हो जो नैनी है? ', 'मुझें नहीं पता! मैं नहीं—शायद आप थोड़ा नाराज महसूस कर रहे हैं। शायद आह, शायद तुमने सोचा था कि तुम पहले शादी करोगे! शायद आप इस तथ्य को बर्दाश्त नहीं कर सकते कि आपके औपचारिक रूप से मोटे दोस्त की शादी आपसे पहले हो रही है!', 'तुम एक मूर्ख हो!', 'हाँ, वे करते हैं! बच्चे की तरह बनना छोड़ो और मुझे अकेला छोड़ो! देखो, तुमने अभी अपना पहला सबक सिख लिया है! ', 'ओहायो में एक गर्भवती महिला है, और उसने हमें चुना है!', 'मुझे अकेले वापस जाने का मन नहीं है, मुझे बहुत अकेलापन महसूस होता है। ओह, तुम मेरे साथ चलो?', 'हर कोई कहता है कि आपके पास पुरुष और महिला दोनों प्रजनन अंग हैं।', 'तुमने एक आदमी को चुम्मा दिया! हे भगवान। एक आदमी बनो!', 'आप पर लज्जा होनी चाहिए! बदसूरत बच्चा आपका निर्णय करता है! ', 'चांडलर कितने साल का था जब उसने पहली बार किसी लड़की के स्तन को छुआ था?', 'बेवकूफ, बूढ़ी, नौकरी के लिए पूर्णतः उपयुक्त हिल्डा।', 'चांडलर! हर कोई--कोई भी मेरा टस्कन फिंगर फूड नहीं खा रहा है, क्योंकि वे सभी फीबे के बर्फीले शंकुओं को भर रहे हैं!', 'अरे, मुझे देखो, मैं एक वेश्या हूँ! ', 'हां, हां, यह बहुत अच्छा होगा! आप समुद्र तट पर लेट सकते हैं और मैं अपनी असफल शादी पर रो सकती हूं। देखो, मैं कैसे मज़ाक बनाती हूं?', 'जॉय, तुम धीरे-धीरे एक महिला में बदल रही हो।', 'इंयू, इंयू, इंयू, इंयू इंयू इंयू इंयू। बेदर्द न्यूड आदमी ने थायमास्टर ख़रीदा है।', 'अरे अरे, तुम लोग, देखो! बदसूरत नंगा आदमी बक्सों में सामान डाल रहा है!', 'मैं समझता हूँ! महिलाएं निराश करती हैं!! ', 'ओह कृपया, और आप जानते थे कि मैं उसे कितना पसंद करता था।', 'देखो, मैंने तुमसे कहा था, मैं किसी क्लिनिक नहीं जा रहा हूँ! मुझे कोई समस्या नहीं है, आप समस्या वाले हैं! आपको \"बच्चा बनना छोड़ो और मुझे अकेला छोड़ दो\" क्लिनिक जाना चाहिए!', 'ठीक है, यदि एक आदमी आपके सिर पर बंदूक रखकर कहे, \"तुम इस बाइक पर सवारी करो वरना मैं... मैं तुम्हें गोली मार दूंगा।\"', '...मुझे उससे जलन हो रही है?! मेरा मतलब है कि वह कौन सोचती है कि वह है ?! राजकुमारी कैरोलीन ?! वह चूसती है।', 'ठीक है देखो, मैं तुम्हें सूची दिखाता हूँ! देखना? हुह? यह नवीनतम बात है! सबके पास एक है! पुरुष! औरत! बच्चे! हर कोई उन्हें ले जा रहा है!', \"अह, 'पेलियोंटोलॉजी विभाग के आकर्षक लोग।' वहाँ एक बड़ी बिक्री वाला कैलेंडर है, है ना?\", 'हाँ, देखो, मेरा मतलब यह नहीं है कि वह शैतान है या कुछ ऐसा है। वह, आप जानते हैं, मेरी वस्तुओं को हमेशा तोड़ देती है। जब मैं आठ साल का था और मैंने उसे मेरे Judy Jetson थर्मोस नहीं दिया, तो उसने उसे बस के नीचे फेंक दिया। और फिर, ओह, फिर रैंडी ब्राउन था, जो ऐसा था... क्या आपके पास कभी ऐसा कोई प्रेमी रहा है जो आपका सबसे अच्छा दोस्त था?', 'तुम जानते हो, हमें शायद डॉक्टर से पूछना चाहिए कि उन्हें क्या पता है कि वह कैसे एक बच्चे को पैदा करते हैं जो आधा मानव और आधा पूर्ण बुराई है।', 'वाह! मैंने कभी इतना स्वस्थ तरीके से ब्रेकअप नहीं किया! वह इस बारे में बहुत वयस्क थी! वह मेरे लिए बहुत अपरिपक्व नहीं लगी! क्या मैंने एक बड़ी गलती कर दी है?', 'यह मजाक है, क्योंकि मुझे लग रहा था कि आप जोए ट्रिबियानी की तरह दिख रहे हैं, पुरुष / महिला।', 'चलिए, मुझे वास्तव में अभी इसे करना नहीं है। मैं एक बहुत भारी सोफ़ा उठा रहा हूँ।', 'मैं तुम्हारी आँखें खोलने की कोशिश कर रहा हूँ, मेरे आदमी! क्या तुम नहीं देखते, अगर तुम फीबे के साथ रहते तो वह हमेशा वहाँ रहती। तुम घर जाने वाले हो, वह वहाँ है। तुम बिस्तर पर जाओ, वह वहाँ है। तुम जागो और ओह हाँ, वह वहाँ है! क्या बकवास है?', 'मुझे बहुत खुशी होगी, लेकिन मुझे अपने माता-पिता से बात करनी होगी। वे हमें बता रहे हैं कि वे आपको गोद लिया है।', 'मैं भी। हाँ, यहाँ बहुत अच्छा है। मैं तुम लोगों के लिए खुश हूँ। हालांकि, तुम्हें ख़मीर पसंद होगा उम्मीद है।', 'चैंडलर, तुम घिनौने हो। कौन शार्क पॉर्न देखता है!', 'उम्म, उन्हें अच्छा नहीं लगता जब आप उनकी व्याकरण को सही करते हैं।', 'हाँ, तुम जानते हो, वह आह, वह मेरी बात कर रही थी जिसके बारे में कल रात कहा था? यह बात साबित हुई है कि वह फिर से मेरे साथ मिलना चाहती है। ओह, मैंने यह पाया है!', 'हे भगवान, सभी पुरुष कहाँ हैं!?', 'आह, मैं एक सस्ती रंडी की तरह मुड़ गया हूँ जिसे एक मोटे आदमी ने अपने चेहरे पर घावों के साथ पेट में मारा है। ओह, मैं बाहर हूँ।', 'नहीं! नहीं, मैं नहीं करूँगा! मैं अब डेटिंग बैरल के नीचे रहूंगा। मेरे नीचे केवल चार तलाक वाले लड़के उह, मर्डरर लड़के, और-और, भूवैज्ञानिक होंगे।', 'रॉस और रेचेल को एक बच्चे के साथ देखना कितना अजीब है। यह अभी इतना बड़ा हो गया है।', 'क्या यह इशारा है? क्योंकि हम आपको प्यार करते हैं, डॉक्टर कॉनेली, लेकिन हमें लगता है कि हम आपको अपने बच्चे नहीं चाहेंगे! वाह, यह एक अनुकूल वातावरण के बारे में बात कर रहे हैं!', 'तुम्हारे कोई मानक नहीं हैं। तुम वह व्यक्ति हो जो पचास मिनट के भीतर तलाक होने के बाद एक आदमी के पीछे जाता है।', 'हाँ, मैंने काम पर इस आदमी से यह नंबर प्राप्त किया था और मैंने एक स्ट्रिपर को रखा है जो तुम्हारे लिए नृत्य करेगी। क्या मैं पत्नी हॉल ऑफ फेम में जा रही हूँ या नहीं?! ', 'छी! क्या आप समलैंगिक हैं?', 'वहाँ एक अनाकर्षक नग्न व्यक्ति सेलो बजा रहा है।', 'ठीक है, यह शानदार होगा! बस आप उसे यह महसूस कराने के लिए बताएं कि आप उसके साथ सेक्स करना चाहते हैं! यह उसे पूरी तरह से अचंभित कर देगा!', 'असली दुनिया में आपका स्वागत है! यह बहुत बेकार है।', 'नहीं। ठीक है, आपको पता है, वह सोचेगी कि मैं आपको एक क्रेडिट कार्ड दे रहा हूँ, लेकिन वास्तव में मैं आपको एक लाइब्रेरी कार्ड दे रहा हूँ।', 'एमिली के चचेरे भाई ने मुझे बाहर निकाल दिया!', 'मुझे पता है कि आप शायद मेरे साथ बाहर नहीं जाना चाहते हैं, क्योंकि मैं बहुत अधिक मजाक करता हूं और मैं कभी गंभीर रिश्ते में नहीं रहा हूं और मुझे लगता है कि मैं तकनीकी रूप से \"डॉक्टर ...\" नहीं हूं।', 'वही तो आप थे?! हमने तो आपके बारे में जूनियर हाई स्कूल में सुना था! क्या आपने सचमुच हवा में अपना मुड़ा हुआ मुँह बनाकर आक्रोशित होकर कहा, \"मैं बदला लूंगा?!\"', 'मुझे एक योजना चाहिए थी, अपने पुरुष से पार करने के लिए। और पुरुष का विपरीत क्या होता है? जाम।', 'मुझे दो पक्के तरीके पता हैं जिनसे आदमी को चुप करा सकते हैं। और उनमें से एक है सेक्स। पुरुष मूर्ख होते हैं।', 'ठीक है, आपने कहा था कि आपके ग्राहक गली में कतार में खड़े थे, इसलिए मैं यहाँ मनोरंजन करने के लिए हूँ!', 'वाह, बहुत अच्छा! हम फिर से शनिवार को बाहर जा रहे हैं। लेकिन मैंने अभी यह जान लिया है कि वह किसी और लड़के के साथ भी मिल रही है। ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pSIhCqSVJhoN"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}